[nltk_data] Downloading package punkt to /home/joel_jang/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [4,5,6,7]
  | Name  | Type                       | Params
-----------------------------------------------------
0 | model | T5ForConditionalGeneration | 2.8 B
-----------------------------------------------------
2.8 B     Trainable params
0         Non-trainable params
2.8 B     Total params
11,399.029Total estimated model params size (MB)
###############################
{'text': 'How did serfdom develop in and then leave Russia ?', 'coarse_label': 2, 'fine_label': 26}
###############################
First elem of self.dataset is  {'text': 'How did serfdom develop in and then leave Russia ?', 'coarse_label': 2, 'fine_label': 26}
Length of dataset retrieving is.. 5452
Epoch 0:   0%|                                                                                              | 0/1363 [00:00<?, ?it/s]
WARNING:datasets.builder:Found cached dataset trec (/home/joel_jang/.cache/huggingface/datasets/trec/default/2.0.0/f2469cab1b5fceec7249fda55360dfdbd92a7a5b545e91ea0f78ad108ffac1c2)
100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 362.86it/s]
/home/joel_jang/miniconda3/envs/zeroshot/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.


































































































































































































Epoch 0: 100%|███████████████████████████████████████████████████████████| 1363/1363 [06:37<00:00,  3.43it/s, loss=0.299, v_num=8p40]save


































































































































































































Epoch 1: 100%|████████████████████████████████████████████████████████████| 1363/1363 [06:37<00:00,  3.43it/s, loss=0.08, v_num=8p40]save



































































































































































































Epoch 2: 100%|██████████████████████████████████████████████████████████| 1363/1363 [06:43<00:00,  3.38it/s, loss=0.0483, v_num=8p40]save











































































































































































































Epoch 3: 100%|██████████████████████████████████████████████████████████| 1363/1363 [07:00<00:00,  3.24it/s, loss=0.0382, v_num=8p40]save






































































































































































































Epoch 4: 100%|██████████████████████████████████████████████████████████| 1363/1363 [06:51<00:00,  3.31it/s, loss=0.0917, v_num=8p40]save
Epoch 4: 100%|██████████████████████████████████████████████████████████| 1363/1363 [08:39<00:00,  2.62it/s, loss=0.0917, v_num=8p40]
Time: 2679.086652994156