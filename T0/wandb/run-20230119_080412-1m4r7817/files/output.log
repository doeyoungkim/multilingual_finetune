[nltk_data] Downloading package punkt to /home/joel_jang/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/home/joel_jang/miniconda3/envs/zeroshot/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/16
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 16 processes
----------------------------------------------------------------------------------------------------
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]
Validation sanity check: 0it [00:00, ?it/s]First elem of self.dataset is  {'en': 'Please come here between two and three this afternoon.\n', 'kor': '오늘 오후 두시에서 세시 사이에 여기로 와 주세요.\n'}
Length of dataset retrieving is.. 1000
Validation sanity check:   0%|                                                                                              | 0/2 [00:00<?, ?it/s]
  | Name  | Type                        | Params
------------------------------------------------------
0 | model | MT5ForConditionalGeneration | 3.7 B
------------------------------------------------------
3.7 B     Trainable params
0         Non-trainable params
3.7 B     Total params
14,970.479Total estimated model params size (MB)
WARNING:datasets.builder:Using custom data configuration default-31b186e58a74258f
WARNING:datasets.builder:Found cached dataset json (/home/joel_jang/.cache/huggingface/datasets/json/default-31b186e58a74258f/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 245.87it/s]
WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /home/joel_jang/.cache/huggingface/datasets/json/default-31b186e58a74258f/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab/cache-6fa19dc9f0152dbb.arrow
/home/joel_jang/miniconda3/envs/zeroshot/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/joel_jang/miniconda3/envs/zeroshot/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.


Validation sanity check: 100%|██████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:13<00:00,  6.70s/it]agg_score is tensor(0., device='cuda:0') 0
enter
First elem of self.dataset is  {'en': '• Made movie and photo download using the SnapBridge app more reliable. \n', 'kor': '• SnapBridge 앱을 사용한 동영상 및 사진 다운로드 기능이 더욱 안정적으로 개선되었습니다.\n'}
Length of dataset retrieving is.. 10000
Training: 0it [00:00, ?it/s]
WARNING:datasets.builder:Using custom data configuration default-6d0501ccb395230e
WARNING:datasets.builder:Found cached dataset json (/home/joel_jang/.cache/huggingface/datasets/json/default-6d0501ccb395230e/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 356.11it/s]
/home/joel_jang/miniconda3/envs/zeroshot/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:110: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 96 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.

































































































Epoch 0:  91%|████████████████████████████████████████████████████████████████████▎      | 627/688 [03:31<00:20,  2.97it/s, loss=2.56, v_num=7817]






















enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:44<00:00,  1.67it/s]

Epoch 0: 100%|████████████████████████████| 688/688 [04:24<00:00,  2.60it/s, loss=2.56, v_num=7817, acc_score_tatoeba=0.232, acc_score_mean=0.232]save
































































































Epoch 1:  91%|█████████████████████████▍  | 625/688 [03:13<00:19,  3.23it/s, loss=2.47, v_num=7817, acc_score_tatoeba=0.232, acc_score_mean=0.232]
























enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:47<00:00,  1.49it/s]

Epoch 1: 100%|████████████████████████████| 688/688 [04:18<00:00,  2.66it/s, loss=2.47, v_num=7817, acc_score_tatoeba=0.252, acc_score_mean=0.252]save

































































































Epoch 2:  91%|█████████████████████████▌  | 627/688 [03:22<00:19,  3.10it/s, loss=2.39, v_num=7817, acc_score_tatoeba=0.252, acc_score_mean=0.252]






















enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:45<00:00,  1.54it/s]

Epoch 2: 100%|████████████████████████████| 688/688 [04:23<00:00,  2.61it/s, loss=2.39, v_num=7817, acc_score_tatoeba=0.267, acc_score_mean=0.267]save
































































































Epoch 3:  91%|█████████████████████████▌  | 627/688 [03:14<00:18,  3.22it/s, loss=2.19, v_num=7817, acc_score_tatoeba=0.267, acc_score_mean=0.267]






















enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:43<00:00,  1.71it/s]

Epoch 3: 100%|████████████████████████████| 688/688 [04:08<00:00,  2.77it/s, loss=2.19, v_num=7817, acc_score_tatoeba=0.263, acc_score_mean=0.263]save































































































Epoch 4:  91%|█████████████████████████▍  | 625/688 [03:12<00:19,  3.24it/s, loss=1.62, v_num=7817, acc_score_tatoeba=0.263, acc_score_mean=0.263]























enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:44<00:00,  1.69it/s]

Epoch 4: 100%|████████████████████████████| 688/688 [04:13<00:00,  2.71it/s, loss=1.62, v_num=7817, acc_score_tatoeba=0.267, acc_score_mean=0.267]save

































































































Epoch 5:  91%|█████████████████████████▌  | 627/688 [03:16<00:19,  3.19it/s, loss=1.55, v_num=7817, acc_score_tatoeba=0.267, acc_score_mean=0.267]






















enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:44<00:00,  1.69it/s]

Epoch 5: 100%|████████████████████████████| 688/688 [04:13<00:00,  2.72it/s, loss=1.55, v_num=7817, acc_score_tatoeba=0.267, acc_score_mean=0.267]save

































































































Epoch 6:  91%|█████████████████████████▍  | 625/688 [03:15<00:19,  3.19it/s, loss=1.55, v_num=7817, acc_score_tatoeba=0.267, acc_score_mean=0.267]























enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:46<00:00,  1.67it/s]

Epoch 6: 100%|████████████████████████████| 688/688 [04:20<00:00,  2.64it/s, loss=1.55, v_num=7817, acc_score_tatoeba=0.264, acc_score_mean=0.264]save
































































































Epoch 7:  91%|█████████████████████████▍  | 625/688 [03:14<00:19,  3.21it/s, loss=1.55, v_num=7817, acc_score_tatoeba=0.264, acc_score_mean=0.264]






















enterating: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 63/63 [00:45<00:00,  1.72it/s]


Epoch 7: 100%|████████████████████████████| 688/688 [04:16<00:00,  2.68it/s, loss=1.55, v_num=7817, acc_score_tatoeba=0.260, acc_score_mean=0.260]save













Epoch 8:  13%|███▌                        | 88/688 [00:27<03:07,  3.20it/s, loss=0.955, v_num=7817, acc_score_tatoeba=0.260, acc_score_mean=0.260]
/home/joel_jang/miniconda3/envs/zeroshot/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:685: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...

Epoch 8:  13%|███▌                        | 89/688 [00:27<03:06,  3.21it/s, loss=0.882, v_num=7817, acc_score_tatoeba=0.260, acc_score_mean=0.260]Time: 3478.192803144455