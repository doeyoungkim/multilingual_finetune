[nltk_data] Downloading package punkt to /home/joel_jang/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [12,13,14,15]
  | Name  | Type                       | Params
-----------------------------------------------------
0 | model | T5ForConditionalGeneration | 2.8 B
-----------------------------------------------------
2.8 B     Trainable params
0         Non-trainable params
2.8 B     Total params
11,399.029Total estimated model params size (MB)
###############################
{'id': 'QuaRel_V1_Fr_0223', 'answer_index': 1, 'logical_forms': ['(infer (speed higher world1) (smoothness higher world2) (smoothness higher world1))', '(infer (speed higher world2) (smoothness higher world1) (smoothness higher world2))'], 'logical_form_pretty': 'qrel(speed, higher, world1) -> qrel(smoothness, higher, world2) ; qrel(smoothness, higher, world1)', 'world_literals': {'world1': ['ice'], 'world2': ['snow']}, 'question': 'Mike was snowboarding on the snow and hit a piece of ice. He went much faster on the ice because _____ is smoother. (A) snow (B) ice'}
###############################
First elem of self.dataset is  {'id': 'QuaRel_V1_Fr_0223', 'answer_index': 1, 'logical_forms': ['(infer (speed higher world1) (smoothness higher world2) (smoothness higher world1))', '(infer (speed higher world2) (smoothness higher world1) (smoothness higher world2))'], 'logical_form_pretty': 'qrel(speed, higher, world1) -> qrel(smoothness, higher, world2) ; qrel(smoothness, higher, world1)', 'world_literals': {'world1': ['ice'], 'world2': ['snow']}, 'question': 'Mike was snowboarding on the snow and hit a piece of ice. He went much faster on the ice because _____ is smoother. (A) snow (B) ice'}
Length of dataset retrieving is.. 1941
Epoch 0:   0%|                                                                                  | 0/486 [00:00<?, ?it/s]
Downloading builder script: 100%|██████████████████████████████████████████████████| 4.15k/4.15k [00:00<00:00, 1.96MB/s]
WARNING:datasets.builder:Found cached dataset quarel (/home/joel_jang/.cache/huggingface/datasets/quarel/default/0.1.0/acb6fe5b05f9a6884ba37d378738bced9f1e96843157521e7cd854f9f6618c5d)
100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 398.69it/s]
/home/joel_jang/miniconda3/envs/zeroshot/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:56: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.






































































Epoch 0: 100%|████████████████████████████████████████████████| 486/486 [02:30<00:00,  3.23it/s, loss=0.235, v_num=6iqz]save








































































Epoch 1: 100%|████████████████████████████████████████████████| 486/486 [02:31<00:00,  3.22it/s, loss=0.247, v_num=6iqz]save







































































Epoch 2: 100%|█████████████████████████████████████████████████| 486/486 [02:33<00:00,  3.17it/s, loss=0.26, v_num=6iqz]save








































































Epoch 3: 100%|████████████████████████████████████████████████| 486/486 [02:33<00:00,  3.16it/s, loss=0.136, v_num=6iqz]save







































































Epoch 4: 100%|████████████████████████████████████████████████| 486/486 [02:34<00:00,  3.14it/s, loss=0.177, v_num=6iqz]save
Epoch 4: 100%|████████████████████████████████████████████████| 486/486 [04:23<00:00,  1.84it/s, loss=0.177, v_num=6iqz]
Time: 1404.46715426445