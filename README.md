

Code for finetuning xsum and 5 different experts for tatoeba(translation).
The code of this repository is based on https://github.com/seonghyeonye/Flipped-Learning
## Setting

The following command will clone the project:
```
git clone https://github.com/doeyoungkim/multilingual_finetune.git
```

Before experimenting, you can make a virtual environment for the project.
```
conda create -n zeroshotlm python=3.8
conda activate zeroshotlm
pip install -r requirements.txt
```

## Dataset download


## Training
We provide commands for all our experiments in README.md under T0 directory. Check [this](./T0/README.md) out!




